{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:30:26.413547Z",
     "iopub.status.busy": "2024-08-07T18:30:26.413133Z",
     "iopub.status.idle": "2024-08-07T18:30:38.548394Z",
     "shell.execute_reply": "2024-08-07T18:30:38.547075Z",
     "shell.execute_reply.started": "2024-08-07T18:30:26.413509Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio\n",
    "from nilearn.masking import compute_brain_mask\n",
    "from transformers import Dinov2Model\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix, \n",
    "    roc_curve\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from pytorch_metric_learning import losses, miners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:30:50.912304Z",
     "iopub.status.busy": "2024-08-07T18:30:50.911975Z",
     "iopub.status.idle": "2024-08-07T18:30:55.984393Z",
     "shell.execute_reply": "2024-08-07T18:30:55.983377Z",
     "shell.execute_reply.started": "2024-08-07T18:30:50.912274Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clip background slices in all three axes\n",
    "def clip_background_slices(image_data, threshold=0):\n",
    "    non_empty_slices_axial = [i for i in range(image_data.shape[2]) if np.max(image_data[:, :, i]) > threshold]\n",
    "    clipped_image_axial = image_data[:, :, non_empty_slices_axial]\n",
    "    non_empty_slices_coronal = [i for i in range(clipped_image_axial.shape[1]) if np.max(clipped_image_axial[:, i, :]) > threshold]\n",
    "    clipped_image_coronal = clipped_image_axial[:, non_empty_slices_coronal, :]\n",
    "    non_empty_slices_sagittal = [i for i in range(clipped_image_coronal.shape[0]) if np.max(clipped_image_coronal[i, :, :]) > threshold]\n",
    "    clipped_image_sagittal = clipped_image_coronal[non_empty_slices_sagittal, :, :]\n",
    "    return clipped_image_sagittal\n",
    "\n",
    "# Function to normalize image data\n",
    "def normalize_image(image_data):\n",
    "    transform = tio.RescaleIntensity(out_min_max=(0, 1))\n",
    "    image_data = transform(torch.tensor(image_data).unsqueeze(0)).squeeze(0).numpy()\n",
    "    return image_data\n",
    "\n",
    "# Function to visualize a few slices\n",
    "def visualize_slices(image_data, title, num_slices=5):\n",
    "    fig, axs = plt.subplots(1, num_slices, figsize=(15, 5))\n",
    "    print(image_data.shape)\n",
    "    for i in range(num_slices):\n",
    "        slice_idx = image_data.shape[2] // (num_slices + 1) * (i + 1)\n",
    "        axs[i].imshow(image_data[:, :, slice_idx], cmap='gray')\n",
    "        axs[i].set_title(f'Slice {slice_idx}')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to preprocess NIfTI file and visualize each step\n",
    "def preprocess_nifti_with_visualization(file_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        # Load NIfTI image\n",
    "        nifti_image = nib.load(file_path)\n",
    "        image_data = nifti_image.get_fdata()\n",
    "        \n",
    "        # Convert sagittal view to axial view\n",
    "        axial_image = np.transpose(image_data, (0, 2, 1))\n",
    "        #visualize_slices(axial_image, \"Axial View of Original Image\")\n",
    "\n",
    "        # Skull stripping\n",
    "        brain_mask = compute_brain_mask(nifti_image, threshold=0.1).get_fdata()\n",
    "\n",
    "        # Check if brain mask is empty\n",
    "        if np.sum(brain_mask) == 0:\n",
    "            print(f\"Skipping {file_path} due to empty brain mask.\")\n",
    "            return None\n",
    "        \n",
    "        # Transpose brain mask to match axial image\n",
    "        brain_mask = np.transpose(brain_mask, (0, 2, 1))\n",
    "        stripped_image = axial_image * brain_mask\n",
    "        #visualize_slices(stripped_image, \"Skull Stripped Image\")\n",
    "\n",
    "        # Resample to (1, 1, 1)\n",
    "        resample = tio.Resample((1, 1, 1), image_interpolation='linear')\n",
    "        subject = tio.Subject(image=tio.ScalarImage(tensor=stripped_image[np.newaxis, ...]))\n",
    "        resampled_subject = resample(subject)\n",
    "        image_data_resampled = resampled_subject.image.data.numpy().squeeze()\n",
    "        #visualize_slices(image_data_resampled, \"Resampled Image\")\n",
    "\n",
    "        # Normalize image data\n",
    "        normalized_image = normalize_image(image_data_resampled)\n",
    "        #visualize_slices(normalized_image, \"Normalized Image\")\n",
    "\n",
    "        # Clip background slices\n",
    "        image_data_clipped = clip_background_slices(normalized_image)\n",
    "        #visualize_slices(image_data_clipped, \"Clipped Image\")\n",
    "\n",
    "        # Extract 50 slices from the middle\n",
    "        middle = image_data_clipped.shape[2] // 2\n",
    "        start = max(0, middle - 25)\n",
    "        end = min(image_data_clipped.shape[2], middle + 25)\n",
    "        extracted_slices = image_data_clipped[:, :, start:end]\n",
    "        #visualize_slices(extracted_slices, \"Extracted Middle Slices\")\n",
    "\n",
    "        # Resize slices to target size\n",
    "        resized_slices = []\n",
    "        for slice_idx in range(extracted_slices.shape[2]):\n",
    "            slice_data = extracted_slices[:, :, slice_idx]\n",
    "            resized_slice = F.interpolate(torch.tensor(slice_data).unsqueeze(0).unsqueeze(0).float(), size=target_size, mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "            resized_slices.append(resized_slice.numpy())  \n",
    "        resized_slices = np.stack(resized_slices, axis=-1)  \n",
    "        #visualize_slices(resized_slices, \"Resized Slices\")\n",
    "\n",
    "        return resized_slices\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load all samples and preprocess\n",
    "root_dir = '/kaggle/input/adni3dataset/ADNI3'\n",
    "classes = {'AD': 0, 'CN': 1, 'MCI': 2 , 'EMCI': 3}\n",
    "samples = []\n",
    "for class_label, class_idx in classes.items():\n",
    "    class_dir = os.path.join(root_dir, f'{class_label}_Collection/ADNI')\n",
    "    for root, _, files in os.walk(class_dir):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.nii'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                preprocessed_data = preprocess_nifti_with_visualization(file_path)\n",
    "                if preprocessed_data is not None:\n",
    "                    samples.append((preprocessed_data, class_idx))\n",
    "\n",
    "\n",
    "all_slices = []\n",
    "for data, class_idx in samples:\n",
    "    for slice_idx in range(data.shape[2]):\n",
    "        slice_data = data[:, :, slice_idx]\n",
    "        all_slices.append((slice_data, class_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtractedSlicesDataset(Dataset):\n",
    "    def __init__(self, slices):\n",
    "        self.slices = slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slice_data, class_idx = self.slices[idx]\n",
    "        \n",
    "        \n",
    "        slice_data = torch.tensor(slice_data).float()\n",
    "        \n",
    "        # Repeat channel dimension to make 3 channels\n",
    "        resized_slice = slice_data.repeat(3, 1, 1)  # Shape: [3, 224, 224]\n",
    "\n",
    "        return resized_slice, class_idx\n",
    "\n",
    "extracted_slices_dataset = ExtractedSlicesDataset(all_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:31:12.318407Z",
     "iopub.status.busy": "2024-08-07T18:31:12.318113Z",
     "iopub.status.idle": "2024-08-07T18:31:12.410615Z",
     "shell.execute_reply": "2024-08-07T18:31:12.409626Z",
     "shell.execute_reply.started": "2024-08-07T18:31:12.318382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataLoader for the full dataset\n",
    "batch_size = 25\n",
    "full_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Full dataset size: {len(extracted_slices_dataset)}\")\n",
    "\n",
    "for i, (slices, label) in enumerate(full_loader):\n",
    "    if i >= 1:  # Visualize only the first batch\n",
    "        break\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"Slices shape:\", slices.shape)\n",
    "    print(\"Labels:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:31:14.640297Z",
     "iopub.status.busy": "2024-08-07T18:31:14.639331Z",
     "iopub.status.idle": "2024-08-07T18:31:15.312680Z",
     "shell.execute_reply": "2024-08-07T18:31:15.311763Z",
     "shell.execute_reply.started": "2024-08-07T18:31:14.640260Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize a few slices\n",
    "num_slices_to_visualize = 5  \n",
    "fig, axes = plt.subplots(1, num_slices_to_visualize, figsize=(15, 5))\n",
    "\n",
    "for i in range(num_slices_to_visualize):\n",
    "    slice_data, class_idx = extracted_slices_dataset[40+i]\n",
    "    slice_data_np = slice_data.numpy()  \n",
    "    \n",
    "    if slice_data_np.shape[0] == 3:\n",
    "        slice_data_np = slice_data_np[0]  # Grayscale, take only one channel\n",
    "    \n",
    "    axes[i].imshow(slice_data_np, cmap='gray')\n",
    "    axes[i].set_title(f\"Class: {class_idx}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:31:49.882609Z",
     "iopub.status.busy": "2024-08-07T18:31:49.881705Z",
     "iopub.status.idle": "2024-08-07T18:31:49.902854Z",
     "shell.execute_reply": "2024-08-07T18:31:49.901881Z",
     "shell.execute_reply.started": "2024-08-07T18:31:49.882566Z"
    }
   },
   "outputs": [],
   "source": [
    "class SplineLinear(nn.Linear):\n",
    "    def __init__(self, in_features: int, out_features: int, init_scale: float = 0.1, **kw) -> None:\n",
    "        self.init_scale = init_scale\n",
    "        super().__init__(in_features, out_features, bias=False, **kw)\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "\n",
    "class ReflectionalSwitchFunction(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            grid_min: float = -2.,\n",
    "            grid_max: float = 2.,\n",
    "            num_grids: int = 8,\n",
    "            exponent: int = 2,\n",
    "            denominator: float = 0.33,  \n",
    "    ):\n",
    "        super().__init__()\n",
    "        grid = torch.linspace(grid_min, grid_max, num_grids)\n",
    "        self.grid = torch.nn.Parameter(grid, requires_grad=False)\n",
    "        self.denominator = denominator  \n",
    "        self.inv_denominator = 1 / self.denominator  \n",
    "\n",
    "    def forward(self, x):\n",
    "        diff = (x[..., None] - self.grid)\n",
    "        diff_mul = diff.mul(self.inv_denominator)\n",
    "        diff_tanh = torch.tanh(diff_mul)\n",
    "        diff_pow = -diff_tanh.mul(diff_tanh)\n",
    "        diff_pow += 1\n",
    "        return diff_pow  \n",
    "\n",
    "\n",
    "class FasterKANLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            input_dim: int,\n",
    "            output_dim: int,\n",
    "            grid_min: float = -2.,\n",
    "            grid_max: float = 2.,\n",
    "            num_grids: int = 8,\n",
    "            exponent: int = 2,\n",
    "            denominator: float = 0.33,\n",
    "            use_base_update: bool = True,\n",
    "            base_activation=F.silu,\n",
    "            spline_weight_init_scale: float = 0.1,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.layernorm = nn.LayerNorm(input_dim)\n",
    "        self.rbf = ReflectionalSwitchFunction(grid_min, grid_max, num_grids, exponent, denominator)\n",
    "        self.spline_linear = SplineLinear(input_dim * num_grids, output_dim, spline_weight_init_scale)\n",
    "\n",
    "    def forward(self, x, time_benchmark=False):\n",
    "        if not time_benchmark:\n",
    "            spline_basis = self.rbf(self.layernorm(x)).view(x.shape[0], -1)\n",
    "        else:\n",
    "            spline_basis = self.rbf(x).view(x.shape[0], -1)\n",
    "        \n",
    "        ret = self.spline_linear(spline_basis)\n",
    "        return ret\n",
    "\n",
    "class FasterKAN(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            layers_hidden: List[int],\n",
    "            grid_min: float = -2.,\n",
    "            grid_max: float = 2.,\n",
    "            num_grids: int = 8,\n",
    "            exponent: int = 2,\n",
    "            denominator: float = 0.33,\n",
    "            use_base_update: bool = True,\n",
    "            base_activation=F.silu,\n",
    "            spline_weight_init_scale: float = 0.667,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "            FasterKANLayer(\n",
    "                in_dim, out_dim,\n",
    "                grid_min=grid_min,\n",
    "                grid_max=grid_max,\n",
    "                num_grids=num_grids,\n",
    "                exponent=exponent,\n",
    "                denominator=denominator,\n",
    "                use_base_update=use_base_update,\n",
    "                base_activation=base_activation,\n",
    "                spline_weight_init_scale=spline_weight_init_scale,\n",
    "            ) for in_dim, out_dim in zip(layers_hidden[:-1], layers_hidden[1:])\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "class kanBlock(nn.Module):\n",
    "    def __init__(self, dim, num_heads=8, hdim_kan=192, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0., attn_drop=0.,\n",
    "                 drop_path=0., act_layer=nn.GELU, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, dropout=attn_drop)\n",
    "        self.drop_path = nn.Identity() if drop_path <= 0. else nn.Dropout(drop_path)\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.kan = FasterKAN(\n",
    "            layers_hidden=[dim, hdim_kan, dim],\n",
    "            grid_min=-2.,\n",
    "            grid_max=2.,\n",
    "            num_grids=8,\n",
    "            exponent=2,\n",
    "            denominator=0.33,\n",
    "            use_base_update=True,\n",
    "            base_activation=act_layer(),\n",
    "            spline_weight_init_scale=0.1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, t, d = x.shape\n",
    "        x_norm1 = self.norm1(x) \n",
    "        attn_output, _ = self.attn(x_norm1, x_norm1, x_norm1)\n",
    "        x = x + self.drop_path(attn_output)\n",
    "        \n",
    "        x_norm2 = self.norm2(x).reshape(-1, d)\n",
    "        kan_output = self.kan(x_norm2).reshape(b, t, d) \n",
    "        x = x + self.drop_path(kan_output)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:35:47.486039Z",
     "iopub.status.busy": "2024-08-07T18:35:47.485027Z",
     "iopub.status.idle": "2024-08-07T18:35:48.327399Z",
     "shell.execute_reply": "2024-08-07T18:35:48.326415Z",
     "shell.execute_reply.started": "2024-08-07T18:35:47.485999Z"
    }
   },
   "outputs": [],
   "source": [
    "class DinoV2KAN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DinoV2KAN, self).__init__()\n",
    "        \n",
    "        # Load the pre-trained DINOv2 model\n",
    "        self.dino = Dinov2Model.from_pretrained('facebook/dinov2-base')\n",
    "        \n",
    "        # Freeze DINOv2 layers\n",
    "        for param in self.dino.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Get the number of features from the DINOv2 model\n",
    "        dino_feature_size = self.dino.config.hidden_size\n",
    "        \n",
    "        # Initialize kanBlock\n",
    "        self.kan_block = kanBlock(\n",
    "            dim=dino_feature_size,\n",
    "            num_heads=12,\n",
    "            hdim_kan=768,\n",
    "            mlp_ratio=4.,\n",
    "            qkv_bias=False,\n",
    "            qk_scale=None,\n",
    "            drop=0.1,\n",
    "            attn_drop=0.1,\n",
    "            drop_path=0.1,\n",
    "            act_layer=nn.GELU,\n",
    "            norm_layer=nn.LayerNorm\n",
    "        )\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.classifier = nn.Linear(dino_feature_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Pass the input through the pre-trained DINOv2 model\n",
    "        outputs = self.dino(x)\n",
    "        features = outputs.last_hidden_state.mean(dim=1)  \n",
    "        \n",
    "        # Pass the features through kanBlock\n",
    "        x = self.kan_block(features.unsqueeze(1)).squeeze(1)\n",
    "        \n",
    "        # Pass through the final classifier\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize contrastive loss and miner\n",
    "contrastive_loss = losses.ContrastiveLoss()\n",
    "miner = miners.MultiSimilarityMiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-07T18:39:31.209052Z",
     "iopub.status.busy": "2024-08-07T18:39:31.208557Z",
     "iopub.status.idle": "2024-08-07T18:41:02.098356Z",
     "shell.execute_reply": "2024-08-07T18:41:02.097172Z",
     "shell.execute_reply.started": "2024-08-07T18:39:31.209017Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0001\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-07\n",
    "batch_size = 25\n",
    "num_classes = 4  \n",
    "k_folds = 10\n",
    "checkpoint_dir = '/kaggle/working/'\n",
    "random_seed = 42  \n",
    "\n",
    "# Create directory for checkpoints if it doesn't exist\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize KFold with a fixed random seed\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Function to calculate specificity\n",
    "def specificity(y_true, y_pred, num_classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    specificities = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i, i]\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        tn = np.sum(cm) - (tp + fn + fp)\n",
    "\n",
    "        specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "        specificities.append(specificity)\n",
    "    \n",
    "    # Return the average specificity across all classes\n",
    "    return np.mean(specificities)\n",
    "\n",
    "\n",
    "def run_folds(fold_start, fold_end):\n",
    "    alpha = 0.1  # Hybrid loss weight for contrastive loss\n",
    "    for fold, (train_ids, test_ids) in enumerate(kf.split(extracted_slices_dataset), start=fold_start):\n",
    "        if fold >= fold_end:\n",
    "            break\n",
    "        \n",
    "        print(f'Fold {fold + 1}/{k_folds}')\n",
    "        \n",
    "        train_sampler = SubsetRandomSampler(train_ids)\n",
    "        test_sampler = SubsetRandomSampler(test_ids)\n",
    "        \n",
    "        # Create loaders\n",
    "        train_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        test_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "        \n",
    "        # Initialize model, optimizer, loss function\n",
    "        model = DinoV2KAN(num_classes=num_classes).to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, eps=eps)\n",
    "        criterion_ce = nn.CrossEntropyLoss()\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training loop\n",
    "            model.train()\n",
    "            train_loss_total = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "\n",
    "            for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} Training', leave=False):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "\n",
    "                # Compute both losses\n",
    "                loss_ce = criterion_ce(outputs, labels)\n",
    "                miner_output = miner(outputs, labels)  \n",
    "                loss_contrastive = contrastive_loss(outputs, labels, miner_output)\n",
    "\n",
    "                # Hybrid loss: alpha * contrastive + (1 - alpha) * cross-entropy\n",
    "                total_loss = alpha * loss_contrastive + (1 - alpha) * loss_ce\n",
    "                total_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                train_loss_total += total_loss.item() * inputs.size(0)\n",
    "\n",
    "            # Test loop\n",
    "            model.eval()\n",
    "            test_loss_total = 0.0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            all_probs = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in tqdm(test_loader, desc=f'Test Epoch {epoch + 1}', leave=False):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss_ce = criterion_ce(outputs, labels)\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    test_loss_total += loss_ce.item() * inputs.size(0)\n",
    "\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    all_predictions.extend(predicted.cpu().numpy())\n",
    "                    all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "        test_loss = test_loss_total / len(test_loader.dataset)\n",
    "        test_acc = 100.0 * test_correct / test_total\n",
    "\n",
    "        # Compute additional metrics\n",
    "        f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "        recall = recall_score(all_labels, all_predictions, average='weighted')  \n",
    "        specificity_avg = specificity(all_labels, all_predictions, num_classes=num_classes)\n",
    "\n",
    "        \n",
    "        all_labels_binarized = label_binarize(all_labels, classes=list(range(num_classes)))\n",
    "        roc_auc = roc_auc_score(all_labels_binarized, np.array(all_probs), multi_class=\"ovr\", average=\"weighted\")\n",
    "\n",
    "        \n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'fold_{fold + 1}_best_model.pth'))\n",
    "\n",
    "        \n",
    "        print(f'\\nMetrics for Fold {fold + 1}:')\n",
    "        print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "        print(f'F1 Score: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}')\n",
    "        print(f'Specificity: {specificity_avg:.4f} | ROC-AUC: {roc_auc:.4f}\\n')\n",
    "\n",
    "        # Plot ROC curve for the fold\n",
    "        plt.figure()\n",
    "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "        plt.plot(fpr, tpr, label=f'Class 1 (area = {roc_auc:.4f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for Fold {fold + 1}')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "run_folds(0, 10)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5504676,
     "sourceId": 9119092,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5509999,
     "sourceId": 9126562,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30716,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
