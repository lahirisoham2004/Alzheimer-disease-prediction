{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:02:36.480433Z",
     "iopub.status.busy": "2024-09-23T15:02:36.480116Z",
     "iopub.status.idle": "2024-09-23T15:02:48.671294Z",
     "shell.execute_reply": "2024-09-23T15:02:48.670023Z",
     "shell.execute_reply.started": "2024-09-23T15:02:36.480403Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import torchio as tio\n",
    "from nilearn.masking import compute_brain_mask\n",
    "from torchvision import models\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:02:48.674735Z",
     "iopub.status.busy": "2024-09-23T15:02:48.674338Z",
     "iopub.status.idle": "2024-09-23T15:02:48.688372Z",
     "shell.execute_reply": "2024-09-23T15:02:48.687358Z",
     "shell.execute_reply.started": "2024-09-23T15:02:48.674656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clip background slices in all three axes\n",
    "def clip_background_slices(image_data, threshold=0):\n",
    "    non_empty_slices_axial = [i for i in range(image_data.shape[2]) if np.max(image_data[:, :, i]) > threshold]\n",
    "    clipped_image_axial = image_data[:, :, non_empty_slices_axial]\n",
    "    non_empty_slices_coronal = [i for i in range(clipped_image_axial.shape[1]) if np.max(clipped_image_axial[:, i, :]) > threshold]\n",
    "    clipped_image_coronal = clipped_image_axial[:, non_empty_slices_coronal, :]\n",
    "    non_empty_slices_sagittal = [i for i in range(clipped_image_coronal.shape[0]) if np.max(clipped_image_coronal[i, :, :]) > threshold]\n",
    "    clipped_image_sagittal = clipped_image_coronal[non_empty_slices_sagittal, :, :]\n",
    "    return clipped_image_sagittal\n",
    "\n",
    "# Function to normalize image data\n",
    "def normalize_image(image_data):\n",
    "    transform = tio.RescaleIntensity(out_min_max=(0, 1))\n",
    "    image_data = transform(torch.tensor(image_data).unsqueeze(0)).squeeze(0).numpy()\n",
    "    return image_data\n",
    "\n",
    "# Function to visualize a few slices\n",
    "def visualize_slices(image_data, title, num_slices=5):\n",
    "    fig, axs = plt.subplots(1, num_slices, figsize=(15, 5))\n",
    "    print(image_data.shape)\n",
    "    for i in range(num_slices):\n",
    "        slice_idx = image_data.shape[2] // (num_slices + 1) * (i + 1)\n",
    "        axs[i].imshow(image_data[:, :, slice_idx], cmap='gray')\n",
    "        axs[i].set_title(f'Slice {slice_idx}')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to preprocess NIfTI file and visualize each step\n",
    "def preprocess_nifti_with_visualization(file_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        # Load NIfTI image\n",
    "        nifti_image = nib.load(file_path)\n",
    "        image_data = nifti_image.get_fdata()\n",
    "        \n",
    "        # Convert sagittal view to axial view\n",
    "        axial_image = np.transpose(image_data, (0, 2, 1))\n",
    "        #visualize_slices(axial_image, \"Axial View of Original Image\")\n",
    "\n",
    "        # Skull stripping\n",
    "        brain_mask = compute_brain_mask(nifti_image, threshold=0.1).get_fdata()\n",
    "\n",
    "        # Check if brain mask is empty\n",
    "        if np.sum(brain_mask) == 0:\n",
    "            print(f\"Skipping {file_path} due to empty brain mask.\")\n",
    "            return None\n",
    "        \n",
    "        # Transpose brain mask to match axial image\n",
    "        brain_mask = np.transpose(brain_mask, (0, 2, 1))\n",
    "        stripped_image = axial_image * brain_mask\n",
    "        #visualize_slices(stripped_image, \"Skull Stripped Image\")\n",
    "\n",
    "        # Resample to (1, 1, 1)\n",
    "        resample = tio.Resample((1, 1, 1), image_interpolation='linear')\n",
    "        subject = tio.Subject(image=tio.ScalarImage(tensor=stripped_image[np.newaxis, ...]))\n",
    "        resampled_subject = resample(subject)\n",
    "        image_data_resampled = resampled_subject.image.data.numpy().squeeze()\n",
    "        #visualize_slices(image_data_resampled, \"Resampled Image\")\n",
    "\n",
    "        # Normalize image data\n",
    "        normalized_image = normalize_image(image_data_resampled)\n",
    "        #visualize_slices(normalized_image, \"Normalized Image\")\n",
    "\n",
    "        # Clip background slices\n",
    "        image_data_clipped = clip_background_slices(normalized_image)\n",
    "        #visualize_slices(image_data_clipped, \"Clipped Image\")\n",
    "\n",
    "        # Extract 50 slices from the middle\n",
    "        middle = image_data_clipped.shape[2] // 2\n",
    "        start = max(0, middle - 25)\n",
    "        end = min(image_data_clipped.shape[2], middle + 25)\n",
    "        extracted_slices = image_data_clipped[:, :, start:end]\n",
    "        #visualize_slices(extracted_slices, \"Extracted Middle Slices\")\n",
    "\n",
    "        # Resize slices to target size\n",
    "        resized_slices = []\n",
    "        for slice_idx in range(extracted_slices.shape[2]):\n",
    "            slice_data = extracted_slices[:, :, slice_idx]\n",
    "            resized_slice = F.interpolate(torch.tensor(slice_data).unsqueeze(0).unsqueeze(0).float(), size=target_size, mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "            resized_slices.append(resized_slice.numpy())  \n",
    "        resized_slices = np.stack(resized_slices, axis=-1)  \n",
    "        #visualize_slices(resized_slices, \"Resized Slices\")\n",
    "\n",
    "        return resized_slices\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load all samples and preprocess\n",
    "root_dir = '/kaggle/input/adni3dataset/ADNI3'\n",
    "classes = {'AD': 0, 'CN': 1, 'MCI': 2 , 'EMCI': 3}\n",
    "samples = []\n",
    "for class_label, class_idx in classes.items():\n",
    "    class_dir = os.path.join(root_dir, f'{class_label}_Collection/ADNI')\n",
    "    for root, _, files in os.walk(class_dir):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.nii'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                preprocessed_data = preprocess_nifti_with_visualization(file_path)\n",
    "                if preprocessed_data is not None:\n",
    "                    samples.append((preprocessed_data, class_idx))\n",
    "\n",
    "\n",
    "all_slices = []\n",
    "for data, class_idx in samples:\n",
    "    for slice_idx in range(data.shape[2]):\n",
    "        slice_data = data[:, :, slice_idx]\n",
    "        all_slices.append((slice_data, class_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:02:48.689911Z",
     "iopub.status.busy": "2024-09-23T15:02:48.689553Z",
     "iopub.status.idle": "2024-09-23T15:02:51.166066Z",
     "shell.execute_reply": "2024-09-23T15:02:51.165255Z",
     "shell.execute_reply.started": "2024-09-23T15:02:48.689881Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExtractedSlicesDataset(Dataset):\n",
    "    def __init__(self, slices):\n",
    "        self.slices = slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slice_data, class_idx = self.slices[idx]\n",
    "        \n",
    "        # Convert slice_data to torch tensor\n",
    "        slice_data = torch.tensor(slice_data).float()\n",
    "        \n",
    "        # Repeat channel dimension to make 3 channels\n",
    "        resized_slice = slice_data.repeat(3, 1, 1)  # Shape: [3, 224, 224]\n",
    "\n",
    "        return resized_slice, class_idx\n",
    "\n",
    "extracted_slices_dataset = ExtractedSlicesDataset(all_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:02:51.167443Z",
     "iopub.status.busy": "2024-09-23T15:02:51.167149Z",
     "iopub.status.idle": "2024-09-23T15:02:51.204417Z",
     "shell.execute_reply": "2024-09-23T15:02:51.203474Z",
     "shell.execute_reply.started": "2024-09-23T15:02:51.167418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataLoader for the full dataset\n",
    "batch_size = 25\n",
    "full_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Full dataset size: {len(extracted_slices_dataset)}\")\n",
    "\n",
    "for i, (slices, label) in enumerate(full_loader):\n",
    "    if i >= 1:  # Visualize only the first batch\n",
    "        break\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"Slices shape:\", slices.shape)\n",
    "    print(\"Labels:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:03:27.164389Z",
     "iopub.status.busy": "2024-09-23T15:03:27.163553Z",
     "iopub.status.idle": "2024-09-23T15:03:27.816142Z",
     "shell.execute_reply": "2024-09-23T15:03:27.815309Z",
     "shell.execute_reply.started": "2024-09-23T15:03:27.164358Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize a few slices\n",
    "num_slices_to_visualize = 5  \n",
    "fig, axes = plt.subplots(1, num_slices_to_visualize, figsize=(15, 5))\n",
    "\n",
    "for i in range(num_slices_to_visualize):\n",
    "    slice_data, class_idx = extracted_slices_dataset[40+i]\n",
    "    slice_data_np = slice_data.numpy()  \n",
    "    \n",
    "    if slice_data_np.shape[0] == 3:\n",
    "        slice_data_np = slice_data_np[0]  # Grayscale, take only one channel\n",
    "    \n",
    "    axes[i].imshow(slice_data_np, cmap='gray')\n",
    "    axes[i].set_title(f\"Class: {class_idx}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:14:49.958681Z",
     "iopub.status.busy": "2024-09-23T15:14:49.958308Z",
     "iopub.status.idle": "2024-09-23T15:14:50.960276Z",
     "shell.execute_reply": "2024-09-23T15:14:50.959315Z",
     "shell.execute_reply.started": "2024-09-23T15:14:49.958640Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, down_sample=False):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.down_sample = down_sample\n",
    "        strides = 2 if down_sample else 1\n",
    "        kernel_size = (3, 3)\n",
    "\n",
    "        # First convolution layer\n",
    "        self.conv_1 = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=strides, padding=1, bias=False)\n",
    "        self.bn_1 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # Second convolution layer\n",
    "        self.conv_2 = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, stride=1, padding=1, bias=False)\n",
    "        self.bn_2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        if down_sample or in_channels != out_channels:\n",
    "            self.res_conv = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 1), stride=strides, bias=False)\n",
    "            self.res_bn = nn.BatchNorm2d(out_channels)\n",
    "        else:\n",
    "            self.res_conv = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Residual connection (shortcut)\n",
    "        residual = x\n",
    "\n",
    "        # First conv + BN + ReLU\n",
    "        x = self.conv_1(x)\n",
    "        x = self.bn_1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Second conv + BN\n",
    "        x = self.conv_2(x)\n",
    "        x = self.bn_2(x)\n",
    "\n",
    "        if self.res_conv is not None:\n",
    "            residual = self.res_conv(residual)\n",
    "            residual = self.res_bn(residual)\n",
    "\n",
    "        # Add residual (skip connection)\n",
    "        x += residual\n",
    "        return F.relu(x)\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ResNet18, self).__init__()\n",
    "        \n",
    "        self.conv_1 = nn.Conv2d(3, 64, kernel_size=(7, 7), stride=2, padding=3)\n",
    "        self.init_bn = nn.BatchNorm2d(64)\n",
    "        self.pool_2 = nn.MaxPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
    "        \n",
    "        # ResNet Blocks\n",
    "        self.res_1_1 = ResNetBlock(64, 64)\n",
    "        self.res_1_2 = ResNetBlock(64, 64)\n",
    "        self.res_2_1 = ResNetBlock(64, 128, down_sample=True)\n",
    "        self.res_2_2 = ResNetBlock(128, 128)\n",
    "        self.res_3_1 = ResNetBlock(128, 256, down_sample=True)\n",
    "        self.res_3_2 = ResNetBlock(256, 256)\n",
    "        self.res_4_1 = ResNetBlock(256, 512, down_sample=True)\n",
    "        self.res_4_2 = ResNetBlock(512, 512)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_1(x)\n",
    "        x = self.init_bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool_2(x)\n",
    "        \n",
    "        # Pass through ResNet blocks\n",
    "        x = self.res_1_1(x)\n",
    "        x = self.res_1_2(x)\n",
    "        x = self.res_2_1(x)\n",
    "        x = self.res_2_2(x)\n",
    "        x = self.res_3_1(x)\n",
    "        x = self.res_3_2(x)\n",
    "        x = self.res_4_1(x)\n",
    "        x = self.res_4_2(x)\n",
    "        \n",
    "        x = self.avg_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FullModel, self).__init__()\n",
    "        \n",
    "        self.base_model_resnet = ResNet18()\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(512, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc4 = nn.Linear(64, 32)\n",
    "        self.bn4 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.fc5 = nn.Linear(32, 32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.fc6 = nn.Linear(32, 4)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base_model_resnet(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn1(F.relu(self.fc1(x)))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn2(F.relu(self.fc2(x)))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn3(F.relu(self.fc3(x)))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn4(F.relu(self.fc4(x)))\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        x = self.bn5(F.relu(self.fc5(x)))\n",
    "        \n",
    "        x = self.fc6(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Model instance\n",
    "model = FullModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-23T15:15:03.210795Z",
     "iopub.status.busy": "2024-09-23T15:15:03.210426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 100\n",
    "learning_rate = 0.001\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-07\n",
    "batch_size = 25\n",
    "num_classes = 4  \n",
    "k_folds = 10\n",
    "checkpoint_dir = '/kaggle/working/'\n",
    "random_seed = 42  # Fixed random seed for reproducibility\n",
    "\n",
    "# Create directory for checkpoints if it doesn't exist\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Initialize device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize KFold with a fixed random seed\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=random_seed)\n",
    "\n",
    "# Function to calculate specificity and sensitivity\n",
    "def specificity_sensitivity(y_true, y_pred, num_classes):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
    "    specificities = []\n",
    "    sensitivities = []\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        tp = cm[i, i]\n",
    "        fn = np.sum(cm[i, :]) - tp\n",
    "        fp = np.sum(cm[:, i]) - tp\n",
    "        tn = np.sum(cm) - (tp + fn + fp)\n",
    "\n",
    "        specificity = tn / (tn + fp) if (tn + fp) != 0 else 0\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) != 0 else 0\n",
    "        \n",
    "        specificities.append(specificity)\n",
    "        sensitivities.append(sensitivity)\n",
    "    \n",
    "    # Return the average specificity and sensitivity across all classes\n",
    "    return np.mean(specificities), np.mean(sensitivities)\n",
    "\n",
    "def run_folds(fold_start, fold_end):\n",
    "    for fold, (train_ids, test_ids) in enumerate(kf.split(extracted_slices_dataset), start=fold_start):\n",
    "        if fold >= fold_end:\n",
    "            break\n",
    "        \n",
    "        print(f'Fold {fold + 1}/{k_folds}')\n",
    "        \n",
    "        train_sampler = SubsetRandomSampler(train_ids)\n",
    "        test_sampler = SubsetRandomSampler(test_ids)\n",
    "        \n",
    "        # Create loaders\n",
    "        train_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "        test_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, sampler=test_sampler)\n",
    "        \n",
    "        # Initialize model, optimizer, loss function\n",
    "        model = FullModel().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate, betas=betas, eps=eps)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "        best_metrics = {}\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training loop\n",
    "            model.train()\n",
    "            train_loss_total = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "\n",
    "            for inputs, labels in tqdm(train_loader, desc=f'Epoch {epoch + 1}/{num_epochs} Training', leave=False):\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                train_total += labels.size(0)\n",
    "                train_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                train_loss_total += loss.item() * inputs.size(0)\n",
    "\n",
    "            train_loss = train_loss_total / len(train_loader.dataset)\n",
    "            train_acc = 100.0 * train_correct / train_total\n",
    "\n",
    "            # Test loop\n",
    "            model.eval()\n",
    "            test_loss_total = 0.0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            all_labels = []\n",
    "            all_predictions = []\n",
    "            all_probs = []\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in tqdm(test_loader, desc=f'Test Epoch {epoch + 1}', leave=False):\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, predicted = torch.max(outputs, 1)\n",
    "                    test_total += labels.size(0)\n",
    "                    test_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    test_loss_total += loss.item() * inputs.size(0)\n",
    "\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "                    all_predictions.extend(predicted.cpu().numpy())\n",
    "                    all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
    "\n",
    "            test_loss = test_loss_total / len(test_loader.dataset)\n",
    "            test_acc = 100.0 * test_correct / test_total\n",
    "\n",
    "            # Compute additional metrics\n",
    "            f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "            precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "            recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "            specificity, sensitivity = specificity_sensitivity(all_labels, all_predictions, num_classes=num_classes)\n",
    "\n",
    "            # Binarize labels for ROC-AUC calculation \n",
    "            all_labels_binarized = label_binarize(all_labels, classes=list(range(num_classes)))\n",
    "            roc_auc = roc_auc_score(all_labels_binarized, np.array(all_probs), multi_class=\"ovr\", average=\"weighted\")\n",
    "\n",
    "            if train_loss < 0.0001:\n",
    "                print(f'Train loss is zero at epoch {epoch + 1}, stopping training.')\n",
    "                break\n",
    "\n",
    "        # Save the model after training\n",
    "        torch.save(model.state_dict(), os.path.join(checkpoint_dir, f'fold_{fold + 1}_model.pth'))\n",
    "\n",
    "        # Print best metrics for the fold after training\n",
    "        print(f'\\nMetrics for Fold {fold + 1}:')\n",
    "        print(f'Test Accuracy: {test_acc:.2f}%')\n",
    "        print(f'F1 Score: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f}')\n",
    "        print(f'Specificity: {specificity:.4f} | Sensitivity: {sensitivity:.4f} | ROC-AUC: {roc_auc:.4f}\\n')\n",
    "\n",
    "        # Plot ROC curve for all classes\n",
    "        plt.figure()\n",
    "        for i in range(num_classes):\n",
    "            fpr, tpr, _ = roc_curve(all_labels_binarized[:, i], np.array(all_probs)[:, i])\n",
    "            plt.plot(fpr, tpr, label=f'Class {i} (area = {roc_auc:.4f})')\n",
    "\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for Fold {fold + 1}')\n",
    "        plt.legend(loc='best')\n",
    "        plt.show()\n",
    "\n",
    "run_folds(0, k_folds)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5504676,
     "sourceId": 9119092,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5509999,
     "sourceId": 9126562,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30716,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
