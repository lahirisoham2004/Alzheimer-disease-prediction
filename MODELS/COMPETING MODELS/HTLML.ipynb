{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T18:58:46.045172Z",
     "iopub.status.busy": "2024-10-07T18:58:46.044755Z",
     "iopub.status.idle": "2024-10-07T18:58:58.475424Z",
     "shell.execute_reply": "2024-10-07T18:58:58.474173Z",
     "shell.execute_reply.started": "2024-10-07T18:58:46.045139Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "import torchio as tio\n",
    "from nilearn.masking import compute_brain_mask\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    f1_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    roc_auc_score, \n",
    "    confusion_matrix, \n",
    "    roc_curve, \n",
    "    accuracy_score\n",
    ")\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T18:58:58.478043Z",
     "iopub.status.busy": "2024-10-07T18:58:58.477722Z",
     "iopub.status.idle": "2024-10-07T18:59:03.474240Z",
     "shell.execute_reply": "2024-10-07T18:59:03.473273Z",
     "shell.execute_reply.started": "2024-10-07T18:58:58.478012Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to clip background slices in all three axes\n",
    "def clip_background_slices(image_data, threshold=0):\n",
    "    non_empty_slices_axial = [i for i in range(image_data.shape[2]) if np.max(image_data[:, :, i]) > threshold]\n",
    "    clipped_image_axial = image_data[:, :, non_empty_slices_axial]\n",
    "    non_empty_slices_coronal = [i for i in range(clipped_image_axial.shape[1]) if np.max(clipped_image_axial[:, i, :]) > threshold]\n",
    "    clipped_image_coronal = clipped_image_axial[:, non_empty_slices_coronal, :]\n",
    "    non_empty_slices_sagittal = [i for i in range(clipped_image_coronal.shape[0]) if np.max(clipped_image_coronal[i, :, :]) > threshold]\n",
    "    clipped_image_sagittal = clipped_image_coronal[non_empty_slices_sagittal, :, :]\n",
    "    return clipped_image_sagittal\n",
    "\n",
    "# Function to normalize image data\n",
    "def normalize_image(image_data):\n",
    "    transform = tio.RescaleIntensity(out_min_max=(0, 1))\n",
    "    image_data = transform(torch.tensor(image_data).unsqueeze(0)).squeeze(0).numpy()\n",
    "    return image_data\n",
    "\n",
    "# Function to visualize a few slices\n",
    "def visualize_slices(image_data, title, num_slices=5):\n",
    "    fig, axs = plt.subplots(1, num_slices, figsize=(15, 5))\n",
    "    print(image_data.shape)\n",
    "    for i in range(num_slices):\n",
    "        slice_idx = image_data.shape[2] // (num_slices + 1) * (i + 1)\n",
    "        axs[i].imshow(image_data[:, :, slice_idx], cmap='gray')\n",
    "        axs[i].set_title(f'Slice {slice_idx}')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "# Function to preprocess NIfTI file and visualize each step\n",
    "def preprocess_nifti_with_visualization(file_path, target_size=(224, 224)):\n",
    "    try:\n",
    "        # Load NIfTI image\n",
    "        nifti_image = nib.load(file_path)\n",
    "        image_data = nifti_image.get_fdata()\n",
    "        \n",
    "        # Convert sagittal view to axial view\n",
    "        axial_image = np.transpose(image_data, (0, 2, 1))\n",
    "        #visualize_slices(axial_image, \"Axial View of Original Image\")\n",
    "\n",
    "        # Skull stripping\n",
    "        brain_mask = compute_brain_mask(nifti_image, threshold=0.1).get_fdata()\n",
    "\n",
    "        # Check if brain mask is empty\n",
    "        if np.sum(brain_mask) == 0:\n",
    "            print(f\"Skipping {file_path} due to empty brain mask.\")\n",
    "            return None\n",
    "        \n",
    "        # Transpose brain mask to match axial image\n",
    "        brain_mask = np.transpose(brain_mask, (0, 2, 1))\n",
    "        stripped_image = axial_image * brain_mask\n",
    "        #visualize_slices(stripped_image, \"Skull Stripped Image\")\n",
    "\n",
    "        # Resample to (1, 1, 1)\n",
    "        resample = tio.Resample((1, 1, 1), image_interpolation='linear')\n",
    "        subject = tio.Subject(image=tio.ScalarImage(tensor=stripped_image[np.newaxis, ...]))\n",
    "        resampled_subject = resample(subject)\n",
    "        image_data_resampled = resampled_subject.image.data.numpy().squeeze()\n",
    "        #visualize_slices(image_data_resampled, \"Resampled Image\")\n",
    "\n",
    "        # Normalize image data\n",
    "        normalized_image = normalize_image(image_data_resampled)\n",
    "        #visualize_slices(normalized_image, \"Normalized Image\")\n",
    "\n",
    "        # Clip background slices\n",
    "        image_data_clipped = clip_background_slices(normalized_image)\n",
    "        #visualize_slices(image_data_clipped, \"Clipped Image\")\n",
    "\n",
    "        # Extract 50 slices from the middle\n",
    "        middle = image_data_clipped.shape[2] // 2\n",
    "        start = max(0, middle - 25)\n",
    "        end = min(image_data_clipped.shape[2], middle + 25)\n",
    "        extracted_slices = image_data_clipped[:, :, start:end]\n",
    "        #visualize_slices(extracted_slices, \"Extracted Middle Slices\")\n",
    "\n",
    "        # Resize slices to target size\n",
    "        resized_slices = []\n",
    "        for slice_idx in range(extracted_slices.shape[2]):\n",
    "            slice_data = extracted_slices[:, :, slice_idx]\n",
    "            resized_slice = F.interpolate(torch.tensor(slice_data).unsqueeze(0).unsqueeze(0).float(), size=target_size, mode='bilinear', align_corners=False).squeeze(0).squeeze(0)\n",
    "            resized_slices.append(resized_slice.numpy())  \n",
    "        resized_slices = np.stack(resized_slices, axis=-1)  \n",
    "        #visualize_slices(resized_slices, \"Resized Slices\")\n",
    "\n",
    "        return resized_slices\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Load all samples and preprocess\n",
    "root_dir = '/kaggle/input/adni3dataset/ADNI3'\n",
    "classes = {'AD': 0, 'CN': 1, 'MCI': 2 , 'EMCI': 3}\n",
    "samples = []\n",
    "for class_label, class_idx in classes.items():\n",
    "    class_dir = os.path.join(root_dir, f'{class_label}_Collection/ADNI')\n",
    "    for root, _, files in os.walk(class_dir):\n",
    "        for file_name in files:\n",
    "            if file_name.endswith('.nii'):\n",
    "                file_path = os.path.join(root, file_name)\n",
    "                preprocessed_data = preprocess_nifti_with_visualization(file_path)\n",
    "                if preprocessed_data is not None:\n",
    "                    samples.append((preprocessed_data, class_idx))\n",
    "\n",
    "\n",
    "all_slices = []\n",
    "for data, class_idx in samples:\n",
    "    for slice_idx in range(data.shape[2]):\n",
    "        slice_data = data[:, :, slice_idx]\n",
    "        all_slices.append((slice_data, class_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T18:59:03.475931Z",
     "iopub.status.busy": "2024-10-07T18:59:03.475470Z",
     "iopub.status.idle": "2024-10-07T18:59:22.818233Z",
     "shell.execute_reply": "2024-10-07T18:59:22.817307Z",
     "shell.execute_reply.started": "2024-10-07T18:59:03.475896Z"
    }
   },
   "outputs": [],
   "source": [
    "class ExtractedSlicesDataset(Dataset):\n",
    "    def __init__(self, slices):\n",
    "        self.slices = slices\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.slices)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        slice_data, class_idx = self.slices[idx]\n",
    "        \n",
    "        # Convert slice_data to torch tensor\n",
    "        slice_data = torch.tensor(slice_data).float()\n",
    "        \n",
    "        # Repeat channel dimension to make 3 channels\n",
    "        resized_slice = slice_data.repeat(3, 1, 1)  # Shape: [3, 224, 224]\n",
    "\n",
    "        return resized_slice, class_idx\n",
    "\n",
    "extracted_slices_dataset = ExtractedSlicesDataset(all_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T18:59:22.819598Z",
     "iopub.status.busy": "2024-10-07T18:59:22.819327Z",
     "iopub.status.idle": "2024-10-07T18:59:22.912663Z",
     "shell.execute_reply": "2024-10-07T18:59:22.911673Z",
     "shell.execute_reply.started": "2024-10-07T18:59:22.819574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create DataLoader for the full dataset\n",
    "batch_size = 25\n",
    "full_loader = DataLoader(extracted_slices_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Print shapes\n",
    "print(f\"Full dataset size: {len(extracted_slices_dataset)}\")\n",
    "\n",
    "for i, (slices, label) in enumerate(full_loader):\n",
    "    if i >= 1:  # Visualize only the first batch\n",
    "        break\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"Slices shape:\", slices.shape)\n",
    "    print(\"Labels:\", label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T18:59:22.914647Z",
     "iopub.status.busy": "2024-10-07T18:59:22.914282Z",
     "iopub.status.idle": "2024-10-07T18:59:23.650890Z",
     "shell.execute_reply": "2024-10-07T18:59:23.649844Z",
     "shell.execute_reply.started": "2024-10-07T18:59:22.914611Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize a few slices\n",
    "num_slices_to_visualize = 5  \n",
    "fig, axes = plt.subplots(1, num_slices_to_visualize, figsize=(15, 5))\n",
    "\n",
    "for i in range(num_slices_to_visualize):\n",
    "    slice_data, class_idx = extracted_slices_dataset[40+i]\n",
    "    slice_data_np = slice_data.numpy()  \n",
    "    \n",
    "    if slice_data_np.shape[0] == 3:\n",
    "        slice_data_np = slice_data_np[0]  # Grayscale, take only one channel\n",
    "    \n",
    "    axes[i].imshow(slice_data_np, cmap='gray')\n",
    "    axes[i].set_title(f\"Class: {class_idx}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-07T19:06:15.898232Z",
     "iopub.status.busy": "2024-10-07T19:06:15.897817Z",
     "iopub.status.idle": "2024-10-07T19:09:43.613065Z",
     "shell.execute_reply": "2024-10-07T19:09:43.611720Z",
     "shell.execute_reply.started": "2024-10-07T19:06:15.898201Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_specificity(y_true, y_pred):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn = cm[0, 0]  # True negatives\n",
    "    fp = cm[0, 1]  # False positives\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    return specificity\n",
    "\n",
    "\n",
    "def extract_features(model, dataloader, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, lbls in tqdm(dataloader, desc=\"Extracting features\", leave=False):\n",
    "            inputs = inputs.to(device)\n",
    "            lbls = lbls.to(device)\n",
    "            \n",
    "            outputs = model.features(inputs)\n",
    "            outputs = torch.flatten(outputs, 1)\n",
    "            \n",
    "            features.append(outputs.cpu())\n",
    "            labels.append(lbls.cpu())\n",
    "    \n",
    "    features = torch.cat(features, dim=0).numpy()\n",
    "    labels = torch.cat(labels, dim=0).numpy()\n",
    "    \n",
    "    return features, labels\n",
    "\n",
    "\n",
    "def initialize_densenet(num_classes):\n",
    "    model = models.densenet201(pretrained=True)\n",
    "    num_features = model.classifier.in_features\n",
    "    model.classifier = nn.Linear(num_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model(model, test_loader, device, num_classes):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(test_loader, desc='Evaluating', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())  \n",
    "\n",
    "    # Accuracy\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    # F1, Precision, and Recall\n",
    "    test_f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    test_precision = precision_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "    test_recall = recall_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "\n",
    "    # Specificity Calculation (One-vs-Rest approach)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    specificity_per_class = []\n",
    "    for i in range(num_classes):\n",
    "        tn = cm.sum() - (cm[i, :].sum() + cm[:, i].sum() - cm[i, i])\n",
    "        fp = cm[:, i].sum() - cm[i, i]\n",
    "        specificity = tn / (tn + fp)\n",
    "        specificity_per_class.append(specificity)\n",
    "    test_specificity = sum(specificity_per_class) / num_classes  # Average specificity across classes\n",
    "\n",
    "    # ROC AUC\n",
    "    try:\n",
    "        if num_classes > 2:\n",
    "            test_roc_auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='weighted')\n",
    "        else:\n",
    "            test_roc_auc = roc_auc_score(all_labels, all_probs[:, 1])\n",
    "    except ValueError:\n",
    "        test_roc_auc = None  \n",
    "\n",
    "    return test_accuracy, test_f1, test_precision, test_recall, test_specificity, test_roc_auc\n",
    "\n",
    "\n",
    "def train_densenet(model, train_loader, num_epochs, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for inputs, labels in tqdm(train_loader, desc=f'Training Epoch {epoch+1}/{num_epochs}', leave=False):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "def run_folds(fold_start, fold_end, dataset, num_classes, num_epochs=100):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    slices = [slice_data for slice_data, _ in dataset.slices]\n",
    "    labels = [class_idx for _, class_idx in dataset.slices]\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=fold_end)\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(skf.split(slices, labels)):\n",
    "        if fold < fold_start:\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nFold {fold+1}/{fold_end}\")\n",
    "        \n",
    "        model = initialize_densenet(num_classes=num_classes).to(device)\n",
    "        \n",
    "        train_slices = [slices[i] for i in train_idx]\n",
    "        test_slices = [slices[i] for i in test_idx]\n",
    "        train_labels = [labels[i] for i in train_idx]\n",
    "        test_labels = [labels[i] for i in test_idx]\n",
    "\n",
    "        train_dataset = ExtractedSlicesDataset(list(zip(train_slices, train_labels)))\n",
    "        test_dataset = ExtractedSlicesDataset(list(zip(test_slices, test_labels)))\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train DenseNet for the specified number of epochs\n",
    "        train_densenet(model, train_loader, num_epochs, criterion, optimizer, device)\n",
    "        \n",
    "        # Extract DenseNet features for GaussianNB\n",
    "        train_features, train_labels = extract_features(model, train_loader, device)\n",
    "        test_features, test_labels = extract_features(model, test_loader, device)\n",
    "        \n",
    "        # Train Gaussian Naive Bayes\n",
    "        gnb_classifier = GaussianNB()\n",
    "        gnb_classifier.fit(train_features, train_labels)\n",
    "        test_predictions = gnb_classifier.predict(test_features)\n",
    "\n",
    "        # Compute GaussianNB metrics\n",
    "        test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "        test_f1 = f1_score(test_labels, test_predictions, average='weighted')\n",
    "        test_precision = precision_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "        test_recall = recall_score(test_labels, test_predictions, average='weighted', zero_division=0)\n",
    "        test_specificity = compute_specificity(test_labels, test_predictions)\n",
    "        try:\n",
    "            test_roc_auc = roc_auc_score(test_labels, test_predictions, multi_class='ovr', average='weighted')\n",
    "        except ValueError:\n",
    "            test_roc_auc = None  \n",
    "        \n",
    "        roc_auc_value = test_roc_auc if test_roc_auc is not None else 'N/A'  \n",
    "        print(f\"Fold {fold+1} - GaussianNB Metrics: Accuracy: {test_accuracy:.4f}, F1: {test_f1:.4f}, Precision: {test_precision:.4f}, \"\n",
    "              f\"Recall: {test_recall:.4f}, Specificity: {test_specificity:.4f}, ROC AUC: {roc_auc_value}\")\n",
    "\n",
    "        # Save DenseNet and GaussianNB models for this fold\n",
    "        torch.save(model.state_dict(), os.path.join('/kaggle/working/', f'fold_{fold+1}_densenet.pth'))\n",
    "        joblib.dump(gnb_classifier, os.path.join('/kaggle/working/', f'fold_{fold+1}_gaussian_nb.pkl'))\n",
    "        \n",
    "        model = None\n",
    "        \n",
    "run_folds(fold_start=0, fold_end=10, dataset=extracted_slices_dataset, num_classes=4)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5504676,
     "sourceId": 9119092,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5509999,
     "sourceId": 9126562,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30716,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
